{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930b5da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch\n",
      "  Downloading open_clip_torch-3.1.0-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: torch>=2.0 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (0.23.0)\n",
      "Requirement already satisfied: regex in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (2025.7.34)\n",
      "Collecting ftfy (from open_clip_torch)\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (0.34.4)\n",
      "Requirement already satisfied: safetensors in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from open_clip_torch) (0.6.2)\n",
      "Collecting timm>=1.0.17 (from open_clip_torch)\n",
      "  Downloading timm-1.0.19-py3-none-any.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from timm>=1.0.17->open_clip_torch) (6.0.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torch>=2.0->open_clip_torch) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from ftfy->open_clip_torch) (0.2.13)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub->open_clip_torch) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from huggingface-hub->open_clip_torch) (2.32.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from tqdm->open_clip_torch) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from requests->huggingface-hub->open_clip_torch) (2025.8.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchvision->open_clip_torch) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\vlad\\miniconda3\\envs\\nlp\\lib\\site-packages (from torchvision->open_clip_torch) (11.3.0)\n",
      "Downloading open_clip_torch-3.1.0-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 16.4 MB/s eta 0:00:00\n",
      "Downloading timm-1.0.19-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 14.3 MB/s eta 0:00:00\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: ftfy, timm, open_clip_torch\n",
      "\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   ------------- -------------------------- 1/3 [timm]\n",
      "   -------------------------- ------------- 2/3 [open_clip_torch]\n",
      "   -------------------------- ------------- 2/3 [open_clip_torch]\n",
      "   ---------------------------------------- 3/3 [open_clip_torch]\n",
      "\n",
      "Successfully installed ftfy-6.3.1 open_clip_torch-3.1.0 timm-1.0.19\n"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad2b815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf3e28ca8c6454eba09626e1f127ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_model.safetensors:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170M/170M [00:26<00:00, 6.38MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot CIFAR-10 accuracy: 93.66%\n"
     ]
    }
   ],
   "source": [
    "# pip install -U torch torchvision timm open_clip_torch\n",
    "\n",
    "import torch, open_clip\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# === Choose a model from recent CLIP-family work ===\n",
    "# Classic strong baseline:\n",
    "MODEL_NAME   = \"ViT-B-32\"\n",
    "PRETRAINED   = \"laion2b_s34b_b79k\"   # from OpenCLIP\n",
    "\n",
    "# Tip: try very recent ones too (if available in your env):\n",
    "# MODEL_NAME, PRETRAINED = \"ViT-SO400M-14-SigLIP\", \"webli\"        # SigLIP family\n",
    "# MODEL_NAME, PRETRAINED = \"EVA02-L-14\", \"laion2b_s9b_b144k\"      # EVA-CLIP family\n",
    "# (List available combos:)\n",
    "# import pprint; pprint.pp(open_clip.list_pretrained())\n",
    "\n",
    "# --- Load model + preprocess ---\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(MODEL_NAME, pretrained=PRETRAINED)\n",
    "tokenizer = open_clip.get_tokenizer(MODEL_NAME)\n",
    "model = model.to(device).eval()\n",
    "\n",
    "# --- Zero-shot on CIFAR-10 (tiny & quick) ---\n",
    "cifar = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=preprocess)\n",
    "loader = DataLoader(cifar, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "classnames = cifar.classes\n",
    "\n",
    "prompts = [f\"a photo of a {c}\" for c in classnames]\n",
    "with torch.no_grad():\n",
    "    text_tokens   = tokenizer(prompts).to(device)\n",
    "    text_features = model.encode_text(text_tokens)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "correct = total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in loader:\n",
    "        images = images.to(device)\n",
    "        image_features = model.encode_image(images)\n",
    "        image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "        # CLIP-style scaled cosine sims\n",
    "        logits = 100.0 * image_features @ text_features.T\n",
    "        preds = logits.argmax(dim=-1).cpu()\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Zero-shot CIFAR-10 accuracy: {100*correct/total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
